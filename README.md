# Airflow_ETL
This project demonstrates an end-to-end data engineering workflow utilizing Airflow, Python, and AWS services. The project involves extracting data from the YouTube API, transforming the data using Python scripts, deploying the workflow on Airflow/EC2, and saving the final result on Amazon S3.

**Overview**
The project aims to showcase a comprehensive data engineering pipeline, covering the following key aspects:

**Data Extraction**
Utilizing the YouTube API to extract relevant data, such as video metrics, comments, or channel information.

**Data Transformation**
Employing Python scripts to perform data transformation tasks, including cleaning, aggregating, and enriching the extracted data.

**Workflow Orchestration**
Using Apache Airflow to orchestrate the entire data engineering workflow, scheduling tasks, and managing dependencies.

**Deployment**
Deploying the workflow on an EC2 instance to ensure scalability and reliability.

**Data Storage**
Saving the transformed data onto Amazon S3, a scalable and durable cloud storage solution.




